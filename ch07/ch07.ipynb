{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.445402100Z",
     "start_time": "2026-01-18T23:05:46.419508600Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "from ch06.ch06 import CHOOSE_MODEL, calc_loss_loader\n",
    "\n",
    "from ch07.previous_chapters import train_model_simple\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode('utf-8')\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.474946500Z",
     "start_time": "2026-01-18T23:05:46.449962800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(f\"Number of entries: {len(data)}\")"
   ],
   "id": "877b88e4503e6a62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.532105100Z",
     "start_time": "2026-01-18T23:05:46.497181600Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Example entry:\\n\", data[50])",
   "id": "977fcf7bbefce214",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.569731800Z",
     "start_time": "2026-01-18T23:05:46.537190Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Another example entry:\\n\", data[999])",
   "id": "a04e40393f4b186e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.599078900Z",
     "start_time": "2026-01-18T23:05:46.572800600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "         f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "46c8da1403ca6c8b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.635561300Z",
     "start_time": "2026-01-18T23:05:46.600598200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "id": "582e7c98b70d86b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.673230Z",
     "start_time": "2026-01-18T23:05:46.637077300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "id": "f18b5f99a0d714c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:46.712959500Z",
     "start_time": "2026-01-18T23:05:46.677856100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(f\"Training set length: {len(train_data)}\")\n",
    "print(f\"Validation set length: {len(val_data)}\")\n",
    "print(f\"Test set length: {len(test_data)}\")\n",
    "\n"
   ],
   "id": "d70370fff051fcc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:50.633082600Z",
     "start_time": "2026-01-18T23:05:46.714997600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n"
   ],
   "id": "bad8003fd6f0e1ca",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:50.974709500Z",
     "start_time": "2026-01-18T23:05:50.726228500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "id": "9e86af87b11ebdbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.019142300Z",
     "start_time": "2026-01-18T23:05:50.995655400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\n",
    "    return inputs_tensor"
   ],
   "id": "22ffee9fdbb965ff",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.082597Z",
     "start_time": "2026-01-18T23:05:51.022701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ],
   "id": "6ac320d3a8275017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.116324100Z",
     "start_time": "2026-01-18T23:05:51.084657200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, target_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "d4eda1287d156457",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.154114200Z",
     "start_time": "2026-01-18T23:05:51.119370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "id": "189c9834acacc207",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.176003700Z",
     "start_time": "2026-01-18T23:05:51.157175100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, target_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        target_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(target_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "1c6f0c4a591d831e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.222563300Z",
     "start_time": "2026-01-18T23:05:51.179058900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "id": "e18fa27979f1adc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.283298Z",
     "start_time": "2026-01-18T23:05:51.224613200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [\n",
    "        [-1.0, 1.0],\n",
    "        [-0.5, 1.5]\n",
    "    ]\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(\n",
    "    logits_1, targets_1\n",
    ")\n",
    "print(loss_1)"
   ],
   "id": "b1087748e14c8706",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.324852600Z",
     "start_time": "2026-01-18T23:05:51.288743600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [\n",
    "        [-1.0, 1.0],\n",
    "        [-0.5, 1.5],\n",
    "        [-0.5, 1.5]\n",
    "    ]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(\n",
    "    logits_2, targets_2\n",
    ")\n",
    "print(loss_2)"
   ],
   "id": "8fb48e53b8f5dd07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.404680100Z",
     "start_time": "2026-01-18T23:05:51.330994100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(\n",
    "    logits_2, targets_3\n",
    ")\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n"
   ],
   "id": "510408567500c8b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.472629200Z",
     "start_time": "2026-01-18T23:05:51.434291800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "id": "7d6d6a88aa8685a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.527858600Z",
     "start_time": "2026-01-18T23:05:51.492502900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())"
   ],
   "id": "5fdc1c9b8c68ae34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Torch CUDA version: 12.8\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.547766700Z",
     "start_time": "2026-01-18T23:05:51.531967500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")\n",
    "\n"
   ],
   "id": "fb9bffa208621466",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.631779600Z",
     "start_time": "2026-01-18T23:05:51.550813700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn = customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "96ebfb5152aa74df",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:05:51.871590Z",
     "start_time": "2026-01-18T23:05:51.634307800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "id": "5c9002021d9a996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T23:56:14.556603Z",
     "start_time": "2026-01-18T23:23:35.122744200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs= {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size = model_size,\n",
    "    models_dir = \"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ],
   "id": "6de70d2958591213",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 50.9kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.20MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 180kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [32:28<00:00, 728kiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 10.3MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 1.22MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 767kiB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:00:26.633993100Z",
     "start_time": "2026-01-19T00:00:26.584757200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n",
    "\n"
   ],
   "id": "6499c1f25e4c803e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:01:18.892113100Z",
     "start_time": "2026-01-19T00:01:14.458056700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx= text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id = 50256\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ],
   "id": "416203598340eb8f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:01:28.601924500Z",
     "start_time": "2026-01-19T00:01:28.539178500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ],
   "id": "5cf5a4dbd1575e57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7.6",
   "id": "3c2a746bbbf7f085"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:02:15.877834Z",
     "start_time": "2026-01-19T00:02:15.855645600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ],
   "id": "90be13167304560b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:03:20.449295200Z",
     "start_time": "2026-01-19T00:03:19.426707900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader,\n",
    "        model,\n",
    "        device,\n",
    "        num_batches=5\n",
    "    )\n",
    "    val_los = calc_loss_loader(\n",
    "        val_loader,\n",
    "        model,\n",
    "        device,\n",
    "        num_batches=5\n",
    "    )\n",
    "\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_los}\")"
   ],
   "id": "a35bfbf79c16adb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.825909376144409\n",
      "Validation loss: 3.7619341373443604\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:05:59.377034600Z",
     "start_time": "2026-01-19T00:04:10.695160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.00005,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training time: {execution_time_minutes:.2f} minutes\")"
   ],
   "id": "219b92d75e7ba107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.503, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.413, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.685\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.669\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.658\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.630\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.302, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.348, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.295, Val loss 0.655\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training time: 1.81 minutes\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:07:03.559378700Z",
     "start_time": "2026-01-19T00:07:01.052870300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(\n",
    "    epochs_tensor,\n",
    "    tokens_seen,\n",
    "    train_losses,\n",
    "    val_losses\n",
    ")"
   ],
   "id": "66691a3fcc41e7cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7-7",
   "id": "6b34fbd42cbb9c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:07:41.268977400Z",
     "start_time": "2026-01-19T00:07:38.583633900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()} \")\n",
    "    print(\"------------------------------\")\n"
   ],
   "id": "fdd4921c48796b54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah. \n",
      "------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud. \n",
      "------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen. \n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:10:39.020841100Z",
     "start_time": "2026-01-19T00:08:54.723721500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-responses.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ],
   "id": "b3599c3cf7b00a87",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:44<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:12:15.993799400Z",
     "start_time": "2026-01-19T00:12:15.904961900Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_data[0])",
   "id": "395e60d9f6551d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:11:49.897139800Z",
     "start_time": "2026-01-19T00:11:47.856323300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-str.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model state dict saved to {file_name}\")"
   ],
   "id": "9aeabb88717d37bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dict saved to gpt2-medium355M-str.pth\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7.8",
   "id": "a4df97a7a4f07b02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:43:07.560384300Z",
     "start_time": "2026-01-19T00:43:07.506342600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter(['name']):\n",
    "        if process_name.lower() in proc.info['name'].lower():\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama is not running. Please start Ollama and try again.\"\n",
    "    )\n",
    "print(\"Ollama is running.\")\n",
    "\n"
   ],
   "id": "cf72274d3719a7c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:49:54.868386900Z",
     "start_time": "2026-01-19T00:49:54.843715300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\",\n",
    "    )\n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "    return response_data\n"
   ],
   "id": "5efe8e6063b3b350",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:50:50.717047200Z",
     "start_time": "2026-01-19T00:50:41.222381800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\n",
    "    prompt=\"What do llamas eat?\",\n",
    "    model=model\n",
    ")\n",
    "print(f\"Response from {model}:\\n{result}\")"
   ],
   "id": "cdc95d2f46bfcfef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from llama3:\n",
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as timothy or alfalfa, is a staple in a llama's diet. They enjoy munching on hay cubes or loose hay.\n",
      "3. Grains: Llamas may receive grains like oats, corn, or barley as part of their daily ration.\n",
      "4. Fruits and vegetables: Fresh fruits and veggies, such as apples, carrots, and sweet potatoes, can be offered as treats or added to their regular diet.\n",
      "5. Minerals: Llamas need access to mineral supplements, which provide essential nutrients like calcium, phosphorus, and salt.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, like willow, alder, or birch.\n",
      "2. Bark: In some cases, they may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a nutritious snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and supplements. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T00:52:50.900191300Z",
     "start_time": "2026-01-19T00:52:37.819104200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ],
   "id": "b90c16e4f8333cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a cheetah.\" an 85 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to that of a cheetah.\n",
      "* Cheetahs are known for their incredible speed, making them a good comparison for a fast car.\n",
      "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that lightning is often used as an example of extremely fast movement in English language, so using a cheetah instead might not be as immediately recognizable or evocative for some readers. However, \"as fast as a cheetah\" is still a clear and effective simile that conveys the idea of the car's speed well!\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I'd score this model response as 40 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly identifies that thunderstorms are associated with clouds (correctly identifying the type of weather phenomenon).\n",
      "* However, it incorrectly specifies the type of cloud as \"cumulus\" instead of \"cumulonimbus\", which is the correct answer.\n",
      "* Additionally, the response lacks precision and clarity, using a vague phrase like \"The type of cloud associated with thunderstorms\" instead of providing a specific and accurate description.\n",
      "\n",
      "Overall, while the model shows some understanding of the topic, it falls short in terms of accuracy and specificity.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is clear and concise, making it easy to understand.\n",
      "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
      "\n",
      "The only reason I wouldn't give myself a perfect score is that the response is quite straightforward and doesn't add any additional value or insights. However, in this case, simplicity and accuracy are key, so I'm happy with my score of 95!\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T01:00:19.033128500Z",
     "start_time": "2026-01-19T01:00:19.016966600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model=model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score '{score}' to int.\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ],
   "id": "cfd1f0c3f5844498",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T01:04:46.126840Z",
     "start_time": "2026-01-19T01:00:22.033988200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores = generate_model_scores(\n",
    "    test_data,\n",
    "    \"model_response\"\n",
    ")\n",
    "\n",
    "print(f\"Number of scores generated: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\")\n"
   ],
   "id": "5b957eca76b1b249",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [04:24<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores generated: 110 of 110\n",
      "Average score: 46.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
